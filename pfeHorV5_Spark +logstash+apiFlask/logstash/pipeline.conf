input {
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["logs"]
    group_id => "logstash_group"
    codec => json
  }
}

filter {
  mutate {
    convert => {
      "duration"           => "integer"
      "src_bytes"          => "integer"
      "dst_bytes"          => "integer"
      "wrong_fragment"     => "integer"
      "hot"                => "integer"
      "logged_in"          => "integer"
      "num_compromised"    => "integer"
      "count"              => "integer"
      "srv_count"          => "integer"
      "serror_rate"        => "float"
      "srv_serror_rate"    => "float"
      "rerror_rate"        => "float"
    }
  }

  ruby {
    code => '
      require "net/http"
      require "json"

      start_time = Time.now.to_f

      uri = URI("http://flask_sup:5001/predict")
      http = Net::HTTP.new(uri.host, uri.port)
      request = Net::HTTP::Post.new(uri.path, { "Content-Type" => "application/json" })

      body = {
        duration: event.get("duration"),
        protocol_type: event.get("protocol_type"),
        service: event.get("service"),
        flag: event.get("flag"),
        src_bytes: event.get("src_bytes"),
        dst_bytes: event.get("dst_bytes"),
        wrong_fragment: event.get("wrong_fragment"),
        hot: event.get("hot"),
        logged_in: event.get("logged_in"),
        num_compromised: event.get("num_compromised"),
        count: event.get("count"),
        srv_count: event.get("srv_count"),
        serror_rate: event.get("serror_rate"),
        srv_serror_rate: event.get("srv_serror_rate"),
        rerror_rate: event.get("rerror_rate")
      }

      request.body = body.to_json

      begin
        response = http.request(request)
        prediction = JSON.parse(response.body)["prediction"]
        event.set("prediction_supervised", prediction.to_i) if prediction
      rescue => e
        event.tag("supervised_prediction_failed")
      end

      end_time = Time.now.to_f
      latency = ((end_time - start_time) * 1000).round(2)
      event.set("latency_ms_supervised", latency)
    '
  }

  ruby {
    code => '
      require "net/http"
      require "json"

      start_time = Time.now.to_f

      uri = URI("http://flask_unsup:5002/predict")
      http = Net::HTTP.new(uri.host, uri.port)
      request = Net::HTTP::Post.new(uri.path, { "Content-Type" => "application/json" })

      body = {
        duration: event.get("duration"),
        protocol_type: event.get("protocol_type"),
        service: event.get("service"),
        flag: event.get("flag"),
        src_bytes: event.get("src_bytes"),
        dst_bytes: event.get("dst_bytes"),
        wrong_fragment: event.get("wrong_fragment"),
        hot: event.get("hot"),
        logged_in: event.get("logged_in"),
        num_compromised: event.get("num_compromised"),
        count: event.get("count"),
        srv_count: event.get("srv_count"),
        serror_rate: event.get("serror_rate"),
        srv_serror_rate: event.get("srv_serror_rate"),
        rerror_rate: event.get("rerror_rate")
      }

      request.body = body.to_json

      begin
        response = http.request(request)
        prediction = JSON.parse(response.body)["prediction"]
        event.set("prediction_unsupervised", prediction.to_i) if prediction
      rescue => e
        event.tag("unsupervised_prediction_failed")
      end

      end_time = Time.now.to_f
      latency = ((end_time - start_time) * 1000).round(2)
      event.set("latency_ms_unsupervised", latency)
    '
  }

  mutate {
    remove_field => ["@version", "log", "input", "ecs", "agent", "host"]
  }

  date {
    match => ["custom_timestamp", "ISO8601"]
    target => "@timestamp"
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    user => "elastic"
    password => "pfe2025"
    data_stream => true
    data_stream_type => "logs"
    data_stream_dataset => "network_dual_model"
    data_stream_namespace => "prod"
  }
}
